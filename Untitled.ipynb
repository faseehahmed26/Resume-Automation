{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da36205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import PyPDF2\n",
    "import os\n",
    "from typing import Dict, List\n",
    "import re\n",
    "from docx import Document\n",
    "from docx.shared import Pt, Inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9781b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf2\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\fasee\\anaconda3\\lib\\site-packages (from pypdf2) (4.12.2)\n",
      "Installing collected packages: pypdf2\n",
      "Successfully installed pypdf2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba40bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CONTACT_INFO:\n",
      "==================================================\n",
      "{'name': 'mm9314@g.rit.edu | +1 585 202 5217 | LinkedIn | Github | Portfolio | Kaggle | Tableau', 'contact': 'mm9314@g.rit.edu | +1 585 202 5217 | LinkedIn | Github | Portfolio | Kaggle | Tableau \\n\\nEDUCATION'}\n",
      "\n",
      "==================================================\n",
      "EDUCATION:\n",
      "==================================================\n",
      "Rochester Institute of Technology, Rochester, NY,  M.S in Data Science\t      Expected May 2025\n",
      "Coursework: Neural Networks, Software Engineering for Data Science, Applied Statistics.                         GPA: 3.84/4.00\n",
      "Jawaharlal Nehru Technological University Hyderabad, B.Tech in Computer Science\t July 2018 - July 2022\n",
      "Coursework: Data Structures and Algorithms, Computer Vision, Artificial Intelligence, NLP \t         GPA: 3.2/4.00\n",
      "\n",
      "==================================================\n",
      "SKILLS:\n",
      "==================================================\n",
      "SEO Content AI, Los Angeles, CA - AI Infrastructure Engineer  \t Nov 2022 - July 2023\n",
      "Enhanced AI-driven content generation efficiency by 25% through leading the integration of transformers within AWS microservices.\n",
      "Developed a Chrome extension using Python, JavaScript, and NodeJS, boosting content quality and generation speed by 40%.\n",
      "Utilized Docker for scalable and reliable deployment across cloud environments via AWS ECS and Fargate.\n",
      "Improved project management and team collaboration through implementing effective development methodologies.\n",
      "Optimized content creation for various use cases by conducting A/B testing with models like LLaMA-13B, Flan-T5, Vicuna-13B, and GPT-3.5.\n",
      "Broadened audience reach by using GCP's Google Translate API for multi-language content translation.\n",
      "Ensured high-quality, error-free content by implementing NLP algorithms with BERT, RoBERTa, and DistilBERT for grammar correction, significantly enhancing user trust.\n",
      "White Label Resell, Los Angeles, CA - Machine Learning Engineer                                      June 2022 - March 2023\n",
      "Automated article generation for digital marketing using AWS Lambda, NodeJS, and API Gateway achieving a 60x reduction in operational costs.\n",
      "Integrated NLP and TensorFlow to analyze and generate over 130K high-quality articles within a week, improving content strategy.\n",
      "Utilized DynamoDB for managing large datasets, ensuring efficient data access and manipulation for content generation processes.\n",
      "Fine-tuned advanced NLP models like BERT, RoBERTa, ALBERT, and DistilBERT for contextual understanding, improving the relevance and quality of generated articles.\n",
      "Explored generative models including GPT-3, GPT-Neo, GPT-J, and GPT-NeoX, to diversify content creation, ensuring a wide range of engaging and unique articles.\n",
      "Leveraged Flan-T5 and T5 Codegen for specific content generation tasks, optimizing for both efficiency and creativity in article production.\n",
      "Developed custom dataset models with Gensim, enhancing thematic accuracy and alignment with marketing goals.\n",
      "Employed MLOps practices with Git and Docker to streamline the development, training, and deployment of machine learning models, facilitating continuous improvement and collaboration.\n",
      "Digital Clinics Research and Services, Hyderabad, India - Data Scientist Intern\tNov 2021 - Dec 2022\n",
      "Developed a sophisticated image classification system using Faster R-CNN, tailored for the nuanced detection of cancerous cells in histopathological images, leveraging TensorFlow for model training and optimization.\n",
      "Engineered a custom segmentation solution with Detectron2, enabling precise delineation of tumor boundaries in medical scans. This approach utilized QuPath for image management and Groovy for scripting complex analysis workflows, significantly enhancing the quality of medical image analysis.\n",
      "Implemented YOLOv5 for the automated screening of pathological slides, achieving unprecedented speed and accuracy in identifying critical diagnostic markers, integrated with OpenCV for real-time image processing and enhancements.\n",
      "Led the integration of MLOps practices, utilizing Docker for containerization and AWS for model deployment, ensuring scalable and robust AI solutions in clinical settings.\n",
      "\n",
      "==================================================\n",
      "EXPERIENCE:\n",
      "==================================================\n",
      "Daiichi Sankyo Inc, Basking Ridge, NJ- R&D Data Governance Intern\t        03/2024 - Present\n",
      "Developed an Informed Consent Forms (ICF) analysis tool using BERT and T5 models, also testing Amazon Bedrock for large-scale language processing.\n",
      "Built a Flask-based frontend for the ICF tool, enabling secure modifications of document classifications based on user permissions.\n",
      "Implemented advanced Large Language Models (LLMs) using Amazon Bedrock, achieving a 20% increase in classification accuracy for detecting explicit prohibitions against data sharing.\n",
      "Utilized Amazon SageMaker for model training and fine-tuning, streamlining the handling of vast volumes of legal documents to ensure scalability and efficiency.\n",
      "Optimized model inference and processing times with EC2 instances, improving overall performance and reliability of the ICF analysis tool.\n",
      "1. Designed an on-premise chatbot delivering instant trial data, cutting access time by 70%.\n",
      "2. Enabled visualizations in the chatbot, improving data comprehension and decision-making efficiency.\n",
      "3. Automated milestone and site tracking, enhancing study performance and reducing missed deadlines by 30%.\n",
      "4. Developed a secure chatbot architecture, ensuring 100% compliance with company data regulations.\n",
      "5. Integrated RAG and AI, achieving 80% improvement in answer accuracy and user trust.\n",
      "Led the migration of clinical data from Veeva Vault to Redshift, establishing an ETL pipeline that ensured data accuracy and improved analytics accessibility.\n",
      "Built indexing and foreign key relationships in Redshift to optimize query performance, enabling high-speed analysis on clinical data.\n",
      "Implemented data validation checks during migration to uphold data governance and regulatory compliance, ensuring reliable and accurate data in the new environment.\n",
      "Collaborating with stakeholders to align the tool's capabilities with Daiichi Sankyo's data-sharing policies, compliance standards, and real-world data requirements.\n",
      "Rochester Institute Of Technology, Rochester, NY- Research Assistant\t        08/2024 - Present\n",
      "Collaborating with Professor Haibo Yang to enhance federated learning models, utilizing gRPC and PyTorch to implement scalable decentralized training algorithms.\n",
      "Analyzing and optimizing distributed environments with PyTorch RPC, reducing communication overhead by 15% through improved data transfer protocols.\n",
      "Leading the integration of the FedDisco algorithm into existing frameworks, accelerating model convergence and reducing training time by 20%.\n",
      "Transitioning between distributed communication algorithms, leveraging FedDisco's adaptive communication strategies for efficient, real-time model updates.\n",
      "Developing advanced distributed training techniques for Large Language Models (LLMs), achieving a 30% increase in system performance and minimizing network latency.\n",
      "Utilizing gRPC for dynamic, secure communication within federated learning models, enhancing data synchronization and increasing overall model accuracy by 10%.\n",
      "\n",
      "==================================================\n",
      "PROJECTS:\n",
      "==================================================\n",
      "Chronic Kidney Disease Predictor \t Nov 2022 - July 20\n",
      "Utilized Python's Pandas and Numpy for data manipulation and preprocessing, ensuring accurate model inputs.\n",
      "Implemented Scikit-learn to develop a logistic regression model, achieving a 98% F1 score for kidney disease prediction.\n",
      "Orchestrated a hybrid application structure, employing Flask for backend functionalities and leveraging the MERN stack for frontend development, to provide an intuitive platform for disease prediction.\n",
      "Employed Matplotlib and Seaborn for data visualization, providing insightful analytics for model performance evaluation.\n",
      "Applied MongoDB for efficient data storage, enabling scalable and secure management of patient data.\n",
      "Beverage Management System                                                                                        June 2022 - March 2023\n",
      "Implemented TensorFlow for creating a convolutional neural network model, achieving real-time beverage detection with 98% accuracy.\n",
      "Used OpenCV for image processing, enhancing the model's ability to recognize various beverages under different conditions.\n",
      "Developed a web application using Flask as the backend and ReactJS for the frontend, offering a seamless user experience.\n",
      "Leveraged PostgreSQL for database management, ensuring robust and reliable storage of inventory data.\n",
      "Incorporated Docker for deploying the application, ensuring consistency across development and production environments.\n",
      "Covid19 Bot  \t Nov 2022 - July 20\n",
      "Developed a chatbot using Python, Flask, and DialogFlow to offer real-time COVID-19 updates via Telegram, enhancing accessibility for users.\n",
      "Implemented Pandas and Numpy for robust data analysis and numerical computations to provide accurate and up-to-date health statistics.\n",
      "Integrated MongoDB to efficiently store and manage user queries and responses, facilitating personalized interaction and data retrieval.\n",
      "Utilized RapidAPI for accessing live COVID-19 data, ensuring the chatbot's information was current and reliable for users seeking instant updates.\n",
      "Flight Price Predictor  \t Nov 2022 - July 20\n",
      "Enhanced the predictive model using Scikit-learn's regression techniques and LSTM networks for dynamic price forecasting, incorporating temporal data analysis.\n",
      "Conducted extensive feature engineering with Pandas, improving model accuracy by identifying key price determinants from historical flight data.\n",
      "Utilized Matplotlib and Seaborn for insightful visualizations of data trends and model performance, aiding in the interpretability of predictions.\n",
      "Deployed the enhanced model on Heroku with a Flask web application interface, providing users with real-time, accurate flight price predictions.\n",
      "Generating Synthetic Anime Data                                                                                        June 2022 - March 2023\n",
      "Leveraged PyTorch and a DC GAN architecture to create high-quality synthetic anime images, significantly enhancing the diversity of our machine learning datasets.\n",
      "Utilized OpenCV for advanced image preprocessing and augmentation tasks, including resizing, normalization, and color adjustments, to prepare images for training, enhancing the model's ability to generate diverse and realistic anime characters.\n",
      "Developed Python scripts to automate the collection and preprocessing of anime images, streamlining the dataset creation process and enabling the efficient generation of large volumes of training data.\n",
      "Applied OpenCV's edge detection and image filtering capabilities to enhance the detail and quality of generated images, ensuring a high degree of realism and variability in the synthetic data.\n",
      "Integrated additional data augmentation techniques such as flipping, rotation, and scaling through OpenCV, further augmenting the training dataset to improve the robustness and generalization of the GAN model.\n",
      "Number Plate Detection  \t Nov 2022 - July 20\n",
      "Deployed YOLOv5 for real-time number plate detection, achieving high accuracy in diverse lighting and environmental conditions.\n",
      "Incorporated OpenCV for advanced image processing tasks, such as adaptive thresholding and contour detection, to improve the accuracy of number plate recognition.\n",
      "Developed a system using Flask as the backend, enabling real-time detection and information processing, with a user-friendly interface for monitoring and alerts.\n",
      "Integrated OpenCV's Gaussian Blur to reduce image noise and improve the model's detection capabilities in varying environmental conditions.\n",
      "Implemented perspective transformation techniques in OpenCV to correct angles and enhance the readability of number plates, ensuring accurate recognition regardless of the vehicle's orientation.\n",
      "\n",
      "==================================================\n",
      "RESEARCH_PAPERS:\n",
      "==================================================\n",
      "Tubules Detection on Breast Carcinoma Whole Slide Images Using Artificial Intelligence (Sep 2022):\n",
      "This groundbreaking research utilized advanced AI deep learning models to accurately detect tubules in breast carcinoma images. The abstract was recognized for its innovation and selected for presentation at the prestigious International C-MIMI Conference at Johns Hopkins University, underscoring the project's contribution to medical imaging and diagnostics.\n",
      "Web-Based Mitosis Detection on Breast Cancer Whole Slide Images Using FasterRCNN and YOLOv5 (Dec 2022):\n",
      "This significant paper, published by the Science and Information (SAI) Organization in the International Journal of Advanced Computer Science Applications (IJACA), detailed the development and application of Faster R-CNN and YOLOv5 for the detection of mitosis in breast cancer whole slide images. The research provided insights into the capabilities of these models in enhancing the accuracy and efficiency of breast cancer grading, demonstrating a pivotal step forward in the application of machine learning in healthcare.\n",
      "ACHIEVEMENTS\n",
      "Kaggle Notebook and Dataset Expert\n",
      "Open Source Contributor at OpenVino(Intel), Ivy\n",
      "Won Best Overall Hack in CSH Hacks Hackathon 2023 : Developed a Chrome extension with a streamlined front-end, leveraging AWS Lambda for backend deployment, which integrates OpenAI's GPT-3.5 to scrutinize terms and conditions, enhancing user vigilance through AWS-powered processing and API Gateway for efficient data handling, encapsulating cloud architecture expertise in delivering a user-centric solution.\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"./Faseeh Curriculum Vitae.docx\"  # Replace with your CV path\n",
    "cv_data = process_cv(pdf_path)\n",
    "\n",
    "# Print extracted sections\n",
    "for section, content in cv_data.items():\n",
    "    print(f\"\\n{'='*50}\\n{section.upper()}:\\n{'='*50}\")\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "397f3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cv(docx_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Process a DOCX CV and extract structured information.\n",
    "    Args:\n",
    "        docx_path (str): Path to the DOCX file\n",
    "    Returns:\n",
    "        Dict: Dictionary containing structured CV information\n",
    "    \"\"\"\n",
    "    doc = Document(docx_path)\n",
    "    cv_data = {}\n",
    "    current_section = None\n",
    "    section_content = []\n",
    "    \n",
    "    # Headers we want to identify\n",
    "    section_headers = {\n",
    "        'EDUCATION': 'education',\n",
    "        'SKILLS': 'skills',\n",
    "        'PROFESSIONAL EXPERIENCE AND INTERNSHIPS': 'experience',\n",
    "        'PROJECTS': 'projects',\n",
    "        'RESEARCH PAPERS': 'research_papers'\n",
    "    }\n",
    "\n",
    "    # First, extract contact information from the first few paragraphs\n",
    "    header_text = '\\n'.join([p.text for p in doc.paragraphs[:3]])\n",
    "    contact_info = {\n",
    "        'name': doc.paragraphs[0].text.strip(),  # First line is usually the name\n",
    "        'contact': header_text  # Store full contact line for later processing\n",
    "    }\n",
    "    cv_data['contact_info'] = contact_info\n",
    "\n",
    "    # Process each paragraph to extract sections\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text = paragraph.text.strip()\n",
    "        if not text:  # Skip empty paragraphs\n",
    "            continue\n",
    "\n",
    "        # Check if this is a section header\n",
    "        is_header = False\n",
    "        for header, section_name in section_headers.items():\n",
    "            if header in text.upper():\n",
    "                # If we were building a previous section, save it\n",
    "                if current_section and section_content:\n",
    "                    cv_data[current_section] = '\\n'.join(section_content)\n",
    "                # Start new section\n",
    "                current_section = section_name\n",
    "                section_content = []\n",
    "                is_header = True\n",
    "                break\n",
    "\n",
    "        # If not a header and we're in a section, add to content\n",
    "        if not is_header and current_section:\n",
    "            section_content.append(text)\n",
    "\n",
    "    # Add the last section\n",
    "    if current_section and section_content:\n",
    "        cv_data[current_section] = '\\n'.join(section_content)\n",
    "\n",
    "    return cv_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92c08d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_openai():\n",
    "    \"\"\"Initialize OpenAI client\"\"\"\n",
    "    client = OpenAI(\n",
    "        organization='org-Qf0ZgkD7gMaJ8A44ouvmZkvt',\n",
    "    )\n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11fb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1731b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a331c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
